#!/usr/bin/env python3
"""
Deep Learning Benchmark Tool - æ·±åº¦å­¦ä¹ åŸºå‡†æµ‹è¯•å·¥å…·
ä¸»ç¨‹åºå…¥å£æ¨¡å—

æ–°å¢åŠŸèƒ½ï¼š
1. KITTIæ•°æ®é›†æ”¯æŒ
2. Faster R-CNNå’ŒFCOSç›®æ ‡æ£€æµ‹æ¨¡å‹
3. è¯­ä¹‰åˆ†å‰²æ¨¡å¼(Segmentation)ï¼ŒåŒ…å«DeepLabã€PSPNetã€UNetç­‰æ¨¡å‹
4. å®Œæ•´çš„æ—¥å¿—è®°å½•ç³»ç»Ÿï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œè¯¦ç»†çš„æ‰§è¡ŒçŠ¶æ€
5. æ¨¡å—åŒ–æ¶æ„ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
6. å‘½ä»¤è¡Œå‚æ•°æ”¯æŒï¼Œå¯è¿›è¡Œæ‰¹é‡æµ‹è¯•å’Œè‡ªåŠ¨åŒ–

ä¸»è¦åŠŸèƒ½ï¼š
1. äº¤äº’å¼è®¾å¤‡é€‰æ‹© (CPU/GPU) - æ”¯æŒè¿”å›ä¸Šä¸€çº§
2. æ¨¡å‹ç±»å‹é€‰æ‹© (Detection/Classification/Segmentation) - æ”¯æŒè¿”å›ä¸Šä¸€çº§
3. æ•°æ®é›†é€‰æ‹© (MNIST/CIFAR-10/COCO/ImageNet/KITTI/Cityscapes) - æ”¯æŒè¿”å›ä¸Šä¸€çº§
4. è‡ªå®šä¹‰æ ·æœ¬æ•°é‡é€‰æ‹© - ä»100åˆ°å…¨éƒ¨æ•°æ®é›†
5. è¯¦ç»†æ€§èƒ½ç»Ÿè®¡å’ŒCSVè¾“å‡º - æŒ‰å¸§/å›¾åƒè¾“å‡ºè¯¦ç»†æ—¶é—´ä¿¡æ¯
6. ç»“æœå¯è§†åŒ–
7. å®Œæ•´çš„æ—¥å¿—è®°å½•ç³»ç»Ÿ
8. å‘½ä»¤è¡Œå‚æ•°æ”¯æŒå’Œæ‰¹é‡æµ‹è¯•

å‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹ï¼š
python main.py --device cuda:0 --model-type classification --model resnet18 --dataset MNIST --samples 100
python main.py --device cpu --model-type detection --model yolov8n --dataset Test-Images --samples 500
python main.py --list-models

**åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹**
```bash
python main.py --list-models
```

**åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†**
```bash
python main.py --list-datasets
```

Platform: Ubuntu 22.04 + NVIDIA GPU support
"""

import sys
import time
import logging
import os

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from utils import setup_logging, check_dependencies, print_dependency_status
from interactive import InteractiveInterface
from cli import CommandLineInterface
from datasets import DatasetLoader
from models import ModelLoader
from rendering import RenderingEngine
from benchmarks import BenchmarkRunner
from monitoring import ResourceMonitor, StatisticsCalculator
from output import ResultExporter, Visualizer

class BenchmarkManager:
    """åŸºå‡†æµ‹è¯•ç®¡ç†å™¨ - ä¸»è¦æ§åˆ¶ç±»"""
    
    def __init__(self):
        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        self.logger, self.log_filename = setup_logging()
        self.logger.info("åŸºå‡†æµ‹è¯•å·¥å…·åˆå§‹åŒ–å¼€å§‹")
        
        # æ£€æŸ¥ä¾èµ–
        self.dependencies = check_dependencies()
        
        # åˆå§‹åŒ–ç•Œé¢ç»„ä»¶
        self.interactive_interface = InteractiveInterface(self.dependencies)
        self.cli_interface = CommandLineInterface(self.dependencies)
        
        # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
        monitor_config = getattr(self, 'monitor_config', {})
        self.resource_monitor = ResourceMonitor(
            enable_gpu_monitoring=not monitor_config.get('disable_gpu_monitor', False),
            sample_interval=monitor_config.get('monitor_interval', 0.1),
            max_samples=monitor_config.get('monitor_samples', 1000)
        )
        self.stats_calculator = StatisticsCalculator()
        
        # åŸºå‡†æµ‹è¯•ç›¸å…³å¯¹è±¡
        self.dataset_loader = None
        self.model_loader = None
        self.rendering_engine = None
        self.benchmark_runner = None
        
        # è¿è¡Œæ•°æ®
        self.configuration = None
        self.model = None
        self.dataloader = None
        self.test_images = None
        self.cli_mode = False
        
        self.logger.info("åŸºå‡†æµ‹è¯•å·¥å…·åˆå§‹åŒ–å®Œæˆ")
    
    def _run_monitor_accuracy_test(self, args):
        """è¿è¡Œç›‘æ§å‡†åº¦æµ‹è¯•"""
        print("ğŸ” MONITORING SYSTEM ACCURACY TEST")
        print("="*50)
        
        try:
            from monitoring import MonitoringOverheadAnalyzer
            
            analyzer = MonitoringOverheadAnalyzer()
            
            # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
            duration = 10.0  # å›ºå®šæµ‹è¯•æ—¶é•¿
            sample_interval = args.monitor_interval
            
            print(f"æµ‹è¯•é…ç½®:")
            print(f"  æµ‹è¯•æ—¶é•¿: {duration}ç§’")
            print(f"  é‡‡æ ·é—´éš”: {sample_interval}ç§’")
            print(f"  GPUç›‘æ§: {'ç¦ç”¨' if args.disable_gpu_monitor else 'å¯ç”¨'}")
            print()
            
            overhead_stats = analyzer.measure_monitoring_overhead(
                duration=duration,
                sample_interval=sample_interval
            )
            
            if overhead_stats:
                analyzer.print_overhead_analysis(overhead_stats)
                
                # åœ¨é™é»˜æ¨¡å¼ä¸‹åªæ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if args.quiet:
                    print(f"RESULT: {overhead_stats['overhead']['relative_percent']:.2f}% overhead")
            else:
                print("âŒ ç›‘æ§å‡†åº¦æµ‹è¯•å¤±è´¥")
                
        except ImportError as e:
            print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
            print("è¯·ç¡®ä¿ monitoring.py æ–‡ä»¶åŒ…å« MonitoringOverheadAnalyzer ç±»")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        try:
            # è§£æå‘½ä»¤è¡Œå‚æ•°
            parser = self.cli_interface.create_parser()
            args = parser.parse_args()
            
            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if args.list_models:
                self.cli_interface.list_available_models()
                return
            
            if args.list_datasets:
                self.cli_interface.list_available_datasets()
                return
            
            if args.test_monitor_accuracy:
                self._run_monitor_accuracy_test(args)
                return
            
            # åˆ¤æ–­ä½¿ç”¨äº¤äº’æ¨¡å¼è¿˜æ˜¯å‘½ä»¤è¡Œæ¨¡å¼
            if self.cli_interface.should_use_interactive_mode(args):
                self._run_interactive_mode()
            else:
                self._run_cli_mode(args)
            
        except KeyboardInterrupt:
            self.logger.warning("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            self.logger.error(f"ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print(f"ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    def _run_interactive_mode(self):
        """è¿è¡Œäº¤äº’æ¨¡å¼"""
        self.logger.info("å¯åŠ¨äº¤äº’æ¨¡å¼")
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] æ·±åº¦å­¦ä¹ åŸºå‡†æµ‹è¯•å·¥å…·å¯åŠ¨")
        
        # æ‰“å°ä¾èµ–çŠ¶æ€
        print_dependency_status(self.dependencies)
        
        # äº¤äº’å¼è®¾ç½®
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹äº¤äº’å¼é…ç½®")
        if not self.interactive_interface.run_interactive_setup():
            self.logger.info("ç”¨æˆ·å–æ¶ˆè®¾ç½®ï¼Œç¨‹åºé€€å‡º")
            return
        
        self.configuration = self.interactive_interface.get_configuration()
        # åœ¨äº¤äº’æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨é»˜è®¤çš„resultsç›®å½•
        self.configuration['output_dir'] = './results'
        self.cli_mode = False
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        self._run_benchmark_pipeline()
    
    def _run_cli_mode(self, args):
        """è¿è¡Œå‘½ä»¤è¡Œæ¨¡å¼"""
        self.logger.info("å¯åŠ¨å‘½ä»¤è¡Œæ¨¡å¼")
        
        # éªŒè¯å‚æ•°
        errors = self.cli_interface.validate_args(args)
        if errors:
            print("å‚æ•°é”™è¯¯:")
            for error in errors:
                print(f"  - {error}")
            print("\nä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
            sys.exit(1)
        
        # è½¬æ¢ä¸ºé…ç½®å¯¹è±¡
        self.configuration = self.cli_interface.args_to_config(args)
        self.cli_mode = True
        
        # è®¾ç½®ç›‘æ§é…ç½®
        self.monitor_config = {
            'disable_gpu_monitor': args.disable_gpu_monitor,
            'monitor_interval': args.monitor_interval,
            'monitor_samples': args.monitor_samples
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ - ä½¿ç”¨ç»å¯¹è·¯å¾„
        output_dir = os.path.abspath(self.configuration['output_dir'])
        self.configuration['output_dir'] = output_dir
        
        if not os.path.exists(output_dir):
            try:
                os.makedirs(output_dir)
                self.logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            except Exception as e:
                self.logger.error(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• {output_dir}: {e}")
                print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• {output_dir}: {e}")
                sys.exit(1)
        
        # æ‰“å°é…ç½®æ‘˜è¦
        self.cli_interface.print_config_summary(self.configuration)
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        self._run_benchmark_pipeline()
    
    def _run_benchmark_pipeline(self):
        """è¿è¡ŒåŸºå‡†æµ‹è¯•æµç¨‹"""
        try:
            # åˆå§‹åŒ–ç»„ä»¶
            self._initialize_components()
            
            # åŠ è½½æ•°æ®é›†
            self._load_dataset()
            
            # åŠ è½½æ¨¡å‹
            self._load_model()
            
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            self._run_benchmark()
            
        except Exception as e:
            self.logger.error(f"åŸºå‡†æµ‹è¯•æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            print(f"åŸºå‡†æµ‹è¯•æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e
    
    def _initialize_components(self):
        """åˆå§‹åŒ–å„ä¸ªç»„ä»¶"""
        self.logger.info("åˆå§‹åŒ–å„ä¸ªç»„ä»¶")
        
        try:
            # åˆå§‹åŒ–æ•°æ®é›†åŠ è½½å™¨
            self.dataset_loader = DatasetLoader(self.configuration['test_samples'])
            
            # åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨
            self.model_loader = ModelLoader(self.configuration['device'])
            
            # åˆå§‹åŒ–æ¸²æŸ“å¼•æ“
            self.rendering_engine = RenderingEngine(self.logger)
            
            self.logger.info("ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e
    
    def _load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        self.logger.info("å¼€å§‹åŠ è½½æ•°æ®é›†")
        if not self.configuration.get('quiet', False):
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹åŠ è½½æ•°æ®é›†")
        
        dataset_name = self.configuration['dataset_name']
        model_type = self.configuration['model_type']
        
        try:
            if model_type == 'classification':
                if dataset_name == 'MNIST':
                    self.dataloader = self.dataset_loader.load_mnist()
                elif dataset_name == 'CIFAR-10':
                    self.dataloader = self.dataset_loader.load_cifar10()
                elif dataset_name == 'ImageNet-Sample':
                    self.dataloader = self.dataset_loader.create_synthetic_classification_dataset()
                else:
                    raise ValueError(f"Unknown classification dataset: {dataset_name}")
            
            elif model_type == 'detection':
                if dataset_name == 'KITTI':
                    self.dataloader = self.dataset_loader.load_kitti()
                elif dataset_name in ['COCO-Sample', 'Test-Images']:
                    self.dataloader, self.test_images = self.dataset_loader.create_synthetic_detection_dataset()
                else:
                    raise ValueError(f"Unknown detection dataset: {dataset_name}")
            
            elif model_type == 'segmentation':
                if dataset_name == 'Cityscapes':
                    self.dataloader = self.dataset_loader.load_cityscapes()
                elif dataset_name == 'Synthetic-Segmentation':
                    self.dataloader = self.dataset_loader.create_synthetic_segmentation_dataset()
                else:
                    raise ValueError(f"Unknown segmentation dataset: {dataset_name}")
            
            self.logger.info("æ•°æ®é›†åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
            print(f"æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        self.logger.info("å¼€å§‹åŠ è½½æ¨¡å‹")
        if not self.configuration.get('quiet', False):
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹åŠ è½½æ¨¡å‹")
        
        try:
            self.model = self.model_loader.load_model(
                self.configuration['model_type'],
                self.configuration['model_info']
            )
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def _run_benchmark(self):
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        self.logger.info("å¼€å§‹è¿è¡ŒåŸºå‡†æµ‹è¯•")
        if not self.configuration.get('quiet', False):
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹è¿è¡ŒåŸºå‡†æµ‹è¯•")
        
        # å¯åŠ¨èµ„æºç›‘æ§
        monitor_thread = self.resource_monitor.start_monitoring()
        
        start_time = time.time()
        
        try:
            # åˆ›å»ºåŸºå‡†æµ‹è¯•è¿è¡Œå™¨
            self.benchmark_runner = BenchmarkRunner(
                model=self.model,
                model_type=self.configuration['model_type'],
                model_info=self.configuration['model_info'],
                device=self.configuration['device'],
                rendering_engine=self.rendering_engine,
                test_samples=self.configuration['test_samples']
            )
            
            # è¿è¡Œå¯¹åº”ç±»å‹çš„åŸºå‡†æµ‹è¯•
            if self.configuration['model_type'] == 'classification':
                timing_results = self.benchmark_runner.run_classification_benchmark(self.dataloader)
            elif self.configuration['model_type'] == 'detection':
                timing_results = self.benchmark_runner.run_detection_benchmark(self.dataloader, self.test_images)
            elif self.configuration['model_type'] == 'segmentation':
                timing_results = self.benchmark_runner.run_segmentation_benchmark(self.dataloader)
            
            end_time = time.time()
            total_time = end_time - start_time
            
            self.logger.info(f"åŸºå‡†æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            # åœæ­¢èµ„æºç›‘æ§
            self.resource_monitor.stop_monitoring()
            
            # è·å–èµ„æºç»Ÿè®¡
            resource_stats = self.resource_monitor.get_resource_stats()
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats = self.stats_calculator.calculate_benchmark_statistics(
                timing_results=timing_results,
                total_time=total_time,
                total_samples=self.benchmark_runner.total_samples,
                model_type=self.configuration['model_type'],
                model_info=self.configuration['model_info'],
                dataset_name=self.configuration['dataset_name'],
                device=self.configuration['device'],
                resource_stats=resource_stats
            )
            
            # æ‰“å°ç»“æœ
            if not self.configuration.get('quiet', False):
                self.stats_calculator.print_results_summary(stats)
            
            # ä¿å­˜ç»“æœå’Œç”Ÿæˆå¯è§†åŒ–
            self._save_results_and_visualizations(stats)
            
        except KeyboardInterrupt:
            self.logger.warning("æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            return None
        except Exception as e:
            self.logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            self.resource_monitor.stop_monitoring()
    
    def _save_results_and_visualizations(self, stats):
        """ä¿å­˜ç»“æœå’Œç”Ÿæˆå¯è§†åŒ–"""
        self.logger.info("å¼€å§‹ä¿å­˜ç»“æœå’Œç”Ÿæˆå¯è§†åŒ–")
        
        try:
            # ç¡®å®šè¾“å‡ºç›®å½•
            output_dir = self.configuration.get('output_dir', './results')
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                self.logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            
            # åˆ›å»ºç»“æœå¯¼å‡ºå™¨ï¼Œä¼ å…¥æ­£ç¡®çš„è¾“å‡ºç›®å½•
            exporter = ResultExporter(
                detailed_results=self.benchmark_runner.detailed_results,
                results_dir=output_dir
            )
            
            # ä¿å­˜CSVç»“æœ
            self.logger.info(f"ä¿å­˜CSVç»“æœåˆ°ç›®å½•: {output_dir}")
            csv_filenames = exporter.save_detailed_csv_results(stats, self.configuration['model_type'])
            
            # åˆ›å»ºå¯è§†åŒ–ï¼ˆå¦‚æœä¸æ˜¯ç¦ç”¨çŠ¶æ€ï¼‰
            plot_files = []
            if not self.configuration.get('no_plots', False):
                self.logger.info(f"ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨åˆ°ç›®å½•: {output_dir}")
                visualizer = Visualizer(
                    detailed_results=self.benchmark_runner.detailed_results,
                    results_dir=output_dir
                )
                plot_files = visualizer.create_visualizations(stats, self.configuration['model_type'])
            
            # æ‰“å°æœ€ç»ˆç»“æœæ–‡ä»¶ä¿¡æ¯
            if not self.configuration.get('quiet', False):
                print(f"\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] æµ‹è¯•å®Œæˆ!")
                print(f"ç»“æœä¿å­˜åœ¨: {output_dir}")
                print(f"æ—¥å¿—æ–‡ä»¶: {self.log_filename}")
                if csv_filenames:
                    print(f"è¯¦ç»†ç»“æœæ–‡ä»¶: {csv_filenames[0]}")
                    if len(csv_filenames) > 1:
                        print(f"æ±‡æ€»ç»“æœæ–‡ä»¶: {csv_filenames[1]}")
                
                if plot_files:
                    print("ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶:")
                    for plot_file in plot_files:
                        print(f"  - {plot_file}")
                elif self.configuration.get('no_plots', False):
                    print("å›¾è¡¨ç”Ÿæˆå·²ç¦ç”¨")
            
            # è®°å½•æœ€ç»ˆå®ŒæˆçŠ¶æ€åˆ°æ—¥å¿—
            self.logger.info("æ‰€æœ‰æµ‹è¯•å’Œè¾“å‡ºç”Ÿæˆå®Œæˆ")
            log_msg = f"ç”Ÿæˆæ–‡ä»¶: æ—¥å¿—-{self.log_filename}, CSV-{len(csv_filenames)}ä¸ª, å›¾è¡¨-{len(plot_files)}ä¸ª"
            self.logger.info(log_msg)
            
            # åœ¨å‘½ä»¤è¡Œæ¨¡å¼ä¸‹ï¼Œæä¾›ç®€æ´çš„æˆåŠŸä¿¡æ¯
            if self.cli_mode and self.configuration.get('quiet', False):
                print(f"SUCCESS: Results saved to {output_dir}")
                print(f"Throughput: {stats['performance']['throughput']:.2f} samples/sec")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»“æœæ—¶å‡ºé”™: {e}")
            print(f"ä¿å­˜ç»“æœæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            raise e

def main():
    """ä¸»å‡½æ•°å…¥å£"""
    benchmark_manager = BenchmarkManager()
    benchmark_manager.run()

if __name__ == "__main__":
    main()